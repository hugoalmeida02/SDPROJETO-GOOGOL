from concurrent import futures
import grpc
import index_pb2
import index_pb2_grpc
from google.protobuf import empty_pb2
import threading
import argparse
import queue
import os
import json
import time

SAVE_INTERVAL = 5
CHECK_REPLICAS_INTERVAL = 5
REPLICAS = []


class IndexServicer(index_pb2_grpc.IndexServicer):
    def __init__(self, host, port, host_gateway, port_gateway):
        self.host = host
        self.port = port
        self.gateway = f"{host_gateway}:{port_gateway}"
        self.lock = threading.Lock()
        self.pending_updates = queue.Queue()
        self.index_file_word = f"words_data_{self.host}_{self.port}.json"
        self.index_file_urls = f"urls_data_{self.host}_{self.port}.json"
        self.load_data()
        self.pending_updates = queue.Queue()

        threading.Thread(target=self.auto_save, daemon=True).start()
        threading.Thread(target=self.process_pending_updates,
                         daemon=True).start()
        threading.Thread(
            target=self.check_replicas_periodically, daemon=True).start()

    def registerIndex(self):
        gateway_channel = grpc.insecure_channel(self.gateway)
        self.gateway_stub = index_pb2_grpc.IndexStub(gateway_channel)
        try:
            response = self.gateway_stub.registerIndexBarrel(
                index_pb2.IndexBarrelRequest(host=self.host, port=self.port))
            if response.valid:
                print("Server registado com sucesso")
                return True
            else:
                print("Nao foi possivel registar server")
                return False
        except grpc.RpcError:
            print("Erro ao registar server. Gateway indisponivel")
            return False

    def load_data(self):
        """Carrega os dados do ficheiro JSON ou cria ficheiro vazio se n√£o existir."""
        # Carregar dados do ficheiro de index, ou criar se n√£o existir
        if os.path.exists(self.index_file_word):
            with open(self.index_file_word, "r") as f:
                self.words_data = json.load(f)
            print(f"‚úÖ Dados carregados do ficheiro {self.index_file_word}")
        else:
            # Se o ficheiro n√£o existir, cria um ficheiro vazio
            with open(self.index_file_word, "w") as f:
                json.dump({}, f)
            print(
                f"‚ö†Ô∏è Ficheiro {self.index_file_word} n√£o encontrado. Criado um novo ficheiro vazio.")
            self.words_data = {}
         # Carregar dados do ficheiro de index, ou criar se n√£o existir
        if os.path.exists(self.index_file_urls):
            with open(self.index_file_urls, "r") as f:
                self.urls_data = json.load(f)
            print(f"‚úÖ Dados carregados do ficheiro {self.index_file_urls}")
        else:
            # Se o ficheiro n√£o existir, cria um ficheiro vazio
            with open(self.index_file_urls, "w") as f:
                json.dump({}, f)
            print(
                f"‚ö†Ô∏è Ficheiro {self.index_file_urls} n√£o encontrado. Criado um novo ficheiro vazio.")
            self.urls_data = {}

    def save_data(self):
        """Guarda os dados no ficheiro JSON."""
        with self.lock:
            with open(self.index_file_word, "w") as f:
                json.dump(self.words_data, f, indent=2)
            with open(self.index_file_urls, "w") as f:
                json.dump(self.urls_data, f, indent=2)

    def auto_save(self):
        """Guarda periodicamente os dados em ficheiros JSON."""
        while True:
            time.sleep(SAVE_INTERVAL)
            self.save_data()

    def sync_with_existing_replicas(self):
        """Sincroniza com outros Index Barrels quando inicia."""

        response = self.gateway_stub.getIndexBarrels(empty_pb2.Empty())

        for server in response.indexInfos:
            if server not in REPLICAS and server != f"{self.host}:{self.port}":
                REPLICAS.append(server)

        for replica in REPLICAS:
            if replica == f"{self.host}:{self.port}":
                continue
            try:
                print(f"üîÑ Tentando sincronizar com {replica}...")
                with grpc.insecure_channel(replica) as channel:
                    stub = index_pb2_grpc.IndexStub(channel)
                    response = stub.getFullIndex(empty_pb2.Empty())

                    with self.lock:
                        for entry in response.palavras:
                            if entry.param0 not in self.words_data:
                                self.words_data[entry.param0] = [entry.param1]
                            else:
                                if entry.param1 not in self.words_data[entry.param0]:
                                    self.words_data[entry.param0].append(
                                        entry.param1)

                        for entry in response.urls:
                            if entry.param0 not in self.urls_data:
                                self.urls_data[entry.param0] = [entry.param1]
                            else:
                                if entry.param1 not in self.urls_data[entry.param0]:
                                    self.urls_data[entry.param0].append(
                                        entry.param1)

                print(f"‚úÖ Sincroniza√ß√£o com {replica} conclu√≠da.")
                return
            except grpc.RpcError:
                print(f"‚ö†Ô∏è Falha ao sincronizar com {replica}")

        print("‚ùå Nenhuma r√©plica dispon√≠vel. Iniciando vazio.")

    def update_replicas_from_gateway(self):
        """Obt√©m a lista de r√©plicas da Gateway."""
        try:
            with grpc.insecure_channel(self.gateway) as channel:
                stub = index_pb2_grpc.IndexStub(channel)
                response = stub.getIndexBarrels(empty_pb2.Empty())

                with self.lock:
                    REPLICAS = [
                        replica for replica in response.indexInfos if replica != f"{self.host}:{self.port}"]
        except grpc.RpcError as e:
            print(f"‚ö†Ô∏è Erro ao contactar a Gateway: {e.details()}")

    def check_replicas_periodically(self):
        """Verifica periodicamente a lista de r√©plicas na Gateway."""
        while True:
            time.sleep(CHECK_REPLICAS_INTERVAL)
            self.update_replicas_from_gateway()

    def reliable_multicast(self, param0, param1, tipo):
        """Envia a atualiza√ß√£o para todas as r√©plicas."""
        def send_update(replica, tipo):
            print(tipo, replica)
            if replica == f"{self.host}:{self.port}":
                return  # Ignorar a pr√≥pria r√©plica
            try:
                with grpc.insecure_channel(replica) as channel:
                    stub = index_pb2_grpc.IndexStub(channel)
                    if tipo == "words":
                        stub.addToIndexWords(index_pb2.AddToIndexRequestWord(
                            word=param0, url=param1, from_multicast=True))
                    if tipo == "urls":
                        stub.addToIndexLinks(index_pb2.AddToIndexRequestLinks(
                            url=param0, link=param1, from_multicast=True))
            except grpc.RpcError:
                print(
                    f"‚ö†Ô∏è Falha ao replicar para {replica}. Guardando para retry.")
                self.pending_updates.put(
                    (param0, param1, tipo, replica))  # Adiciona √† fila

        # Criar threads para enviar atualiza√ß√µes em paralelo
        threads = [threading.Thread(target=send_update, args=(
            replica, tipo,))for replica in REPLICAS]
        for thread in threads:
            thread.start()
        for thread in threads:
            thread.join()  # Esperar todas as threads terminarem

    def process_pending_updates(self):
        """Reenvia mensagens falhadas periodicamente."""
        while True:
            time.sleep(5)  # Tentar reenviar a cada 5 segundos
            while not self.pending_updates.empty():
                param0, param1, tipo, replica = self.pending_updates.get()
                print(
                    f"üîÑ Reenviando atualiza√ß√£o para {replica}: {param0} -> {param1}")
                try:
                    with grpc.insecure_channel(replica) as channel:
                        stub = index_pb2_grpc.IndexStub(channel)
                        if tipo == "words":
                            stub.addToIndexWords(index_pb2.AddToIndexRequestWord(
                                word=param0, url=param1, from_multicast=True))
                        if tipo == "urls":
                            stub.addToIndexLinks(index_pb2.AddToIndexRequestLinks(
                                url=param0, link=param1, from_multicast=True))
                except grpc.RpcError:
                    print(
                        f"‚ö†Ô∏è Falha ao reenviar para {replica}. Guardando novamente.")
                    self.pending_updates.put(
                        (param0, param1, tipo, replica))  # Reinsere na fila

    def addToIndexWords(self, request, context):
        with self.lock:
            if request.word not in self.words_data:
                self.words_data[request.word] = [request.url]
            else:
                if request.url not in self.words_data[request.word]:
                    self.words_data[request.word].append(request.url)

        if not request.from_multicast:
            threading.Thread(target=self.reliable_multicast, args=(
                request.word, request.url, "words"), daemon=True).start()
        return empty_pb2.Empty()

    def addToIndexLinks(self, request, context):
        with self.lock:
            if request.url not in self.urls_data:
                self.urls_data[request.url] = {}
                self.urls_data[request.url]["title"] = request.title
                self.urls_data[request.url]["quote"] = request.quote
                self.urls_data[request.url]["urls"] = []

            if request.link not in self.urls_data[request.url]:
                self.urls_data[request.url]["urls"].append(request.link)

        if not request.from_multicast:
            threading.Thread(target=self.reliable_multicast, args=(
                request.url, request.link, "urls"), daemon=True).start()
        return empty_pb2.Empty()

    def searchWord(self, request, context):
        with self.lock:
            palavras = request.words.split()

            if not palavras:
                return index_pb2.SearchWordResponse(urls=[index_pb2.WordInfo()])

            # Verifica se a primeira palavra existe no dicion√°rio
            if palavras[0] in self.words_data:
                urls_comuns = set(self.words_data[palavras[0]])
            else:

                return index_pb2.SearchWordResponse(urls=[index_pb2.WordInfo()])

            for palavra in palavras[1:]:
                if palavra in self.words_data:
                    urls_comuns &= set(self.words_data[palavra])
                else:
                    return index_pb2.SearchWordResponse(urls=[index_pb2.WordInfo()])

            urls_com_importancia = []
            for url in urls_comuns:
                importancia = 0
                for urls in self.urls_data.items():
                    if url in urls[1]["urls"]:
                        importancia += 1
                urls_com_importancia.append(
                    [url, self.urls_data[url]["title"], self.urls_data[url]["quote"], importancia])

            urls_ordenados = sorted(
                urls_com_importancia, key=lambda x: x[3], reverse=True)

            urls = []
            for url, title, quote, _ in urls_ordenados:
                url_info = index_pb2.WordInfo()
                url_info.url = url
                url_info.title = title
                url_info.quote = quote
                urls.append(url_info)

        return index_pb2.SearchWordResponse(urls=urls)

    def searchBacklinks(self, request, context):
        with self.lock:
            backlinks = []
            for urls in self.urls_data.items():
                if request.url in urls[1]["urls"]:
                    backlinks.append(urls[0])
        
        return index_pb2.SearchBacklinksResponse(backlinks=backlinks)


    def getFullIndex(self, request, context):
        """Envia todo o √≠ndice para um novo servidor que est√° a sincronizar."""
        with self.lock:
            entries_palavras = []
            entries_urls = []
            for palavra, urls in self.words_data.items():
                for url in urls:
                    entry = index_pb2.IndexEntry(param0=palavra, param1=url)
                    entries_palavras.append(entry)
            for url, links in self.urls_data.items():
                for link in links:
                    entry = index_pb2.IndexEntry(param0=url, param1=link)
                    entries_urls.append(entry)

        return index_pb2.FullIndexResponse(palavras=entries_palavras, urls=entries_urls)


def run(host, port, host_gateway, port_gateway):
    try:
        server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))
        index_service = IndexServicer(host, port, host_gateway, port_gateway)
        if index_service.registerIndex():
            index_service.sync_with_existing_replicas()
            index_pb2_grpc.add_IndexServicer_to_server(index_service, server)
            server.add_insecure_port(f"{host}:{port}")
            server.start()
            print(f"Server started on {host}:{port}")

            server.wait_for_termination()
    except KeyboardInterrupt:
        print("\nStopping the Index Barrel...")
        return


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Index Barrel")
    parser.add_argument("--host", type=str, required=True,
                        help="Host para o servidor gRPC")
    parser.add_argument("--port", type=str, required=True,
                        help="Porta para o servidor gRPC")
    parser.add_argument("--host_gateway", type=str, required=True,
                        help="Host para o servidor gRPC")
    parser.add_argument("--port_gateway", type=str, required=True,
                        help="Porta para o servidor gRPC")
    args = parser.parse_args()

    run(args.host, args.port, args.host_gateway, args.port_gateway)
